{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chinese-candidate",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Notebook Parameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-garbage",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "matched-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google Colab settings'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Google Colab settings\"\"\"\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surprising-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 281 µs (started: 2021-03-01 10:58:32 +01:00)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Jupyter settings\"\"\"\n",
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Pylint parameters\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# Measure Runtime\n",
    "# !pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-eugene",
   "metadata": {},
   "source": [
    "### Imported Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-somerset",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "#### Packages Usually Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decreased-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 794 ms (started: 2021-03-01 10:58:37 +01:00)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Packages for manipulation of vectors, arrays, dataframes\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None) # Change display settings of pandas\n",
    "\n",
    "\"\"\"Packages for cleaning dataset\"\"\"\n",
    "import json\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "\"\"\"Packages for data visualization\"\"\"\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-playback",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "#### Packages Specific to the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quantitative-nightmare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 533 ms (started: 2021-03-01 10:58:38 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# natural language processing: n-gram ranking\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# add appropriate words that will be ignored in the analysis\n",
    "ADDITIONAL_STOPWORDS = ['covfefe']\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-cooperation",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Computational Extraction of N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-imagination",
   "metadata": {},
   "source": [
    "Method following the tutorial [From DataFrame to N-Grams](https://towardsdatascience.com/from-dataframe-to-n-grams-e34e29df3460)   \n",
    "> A quick-start guide to creating and visualizing n-gram ranking using `nltk` for natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-portsmouth",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "muslim-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.97 s (started: 2021-03-01 10:58:41 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Load the whole clean dataset\n",
    "file ='../raw_data/ocr_labeled.csv'\n",
    "off_df_base = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "determined-stick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.7 ms (started: 2021-03-01 10:58:46 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Deep copy of the dataframe to avoid to reload it\n",
    "off = off_df_base.copy()  # Renew the DataFrame\n",
    "df = off[:10000] # Sample of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "excellent-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (434896, 6)\n",
      "\n",
      "Columns types of the dataset: \n",
      "barcode           int64\n",
      "clean_text       object\n",
      "fr_text          object\n",
      "source           object\n",
      "pnns_groups_1    object\n",
      "pnns_groups_2    object\n",
      "dtype: object\n",
      "\n",
      "Head of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>fr_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pnns_groups_1</th>\n",
       "      <th>pnns_groups_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3199660476748</td>\n",
       "      <td>ne eleve abattu en bretagne les eleveurs de bretagne decoupe de podlet noir ferfier labe caracteristiques certifiees fermiereleve en plein air duree delevage  jours minimum  de cereales alimente avec  de vegetaux mineraux et vitamines do mation  voir etiquette poidsprix a conserver entre oc et c a consommer cuit a caeurdate limite de co  le rheu certifie par certisimmeuble le millepertuis les landes dap produit frais classe a pour toute reclamation sadresser a fermiers dargoat bp ploufragan decoupe et conditionne par ldc bretagne bp  quintin homologation n la   ce  abattoir agree nfr  ce fltplt ferlr sat elbretpf  origine france yo volaise prixtrg poids net prix a payer kg lot    r consommer jusqu au r conserver entre o c et  c  expedie le  loc bretagne  lanfains  e a   au trit aste wwwconsignesdetrfr</td>\n",
       "      <td>NE\\nELEVE\\nABATTU\\nEN BRETAGNE\\nLES ÉLEVEURS\\nDE BRETAGNE\\nDécoupe de\\nPodlet noir\\nferfier\\nlabe\\nCaractéristiques certifiées: Fermier-élevé en plein air. Durée d'élevage 81 jours minimum.\\n75% de céréales.\\nAlimenté avec 100% de végétaux, minéraux et vitamines do mation : voir étiquette poids/prix\\nA conserver entre O°C et +4°C -A consommer cuit à caeur-Date limite de co 35650 Le Rheu\\nCertifié par: CERTIS-Immeuble Le Millepertuis- Les Landes d'Ap\\nProduit frais\\nClasse A\\nPour toute réclamation, s'adresser à\\nFERMIERS D'ARGOAT: BP77-22440 PLOUFRAGAN\\nDécoupé et conditionné par: LDC Bretagne BP 256-2280 QUINTIN\\nHomologation\\nN° LA/02/75\\n099 002\\nCE\\n2\\nAbattoir agréé n'FR 22.099.002 CE\\n2FLT.PLT FER.LR SAT\\nEL.BRET.PF 2\\nORIGINE France\\nyo\\nVOLAISE\\nPrixtrg\\nPoids net\\nPrix a payer\\n0,240kg\\nLot\\n005809 19 45\\nR consommer jusqu au\\nR conserver entre O C et +4 C\\n10/04/18\\nExpedie Le 30/03/18\\nLOC BRETAGNE 22 LANFAINS\\n22.039.002\\ne01\\n172225-0/196A\\n3 19966014\\nAU TRIT ASTE\\nwww.CONSIGNESDETRFR\\n</td>\n",
       "      <td>/319/966/047/6748/1.json</td>\n",
       "      <td>fish meat eggs</td>\n",
       "      <td>meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3199660219192</td>\n",
       "      <td>ker chant  local decoupes de poulet conditionne par ldc bretagne lanfains   rais classe a origine france prodtre  et c offre speciale ne eleve prepare  local dans notre region cuisdej plt sat kerchant fx  origine france volaille francaise prixkg paids net prin apayer kg to  a consommer jusqu au  r conserver entre d c et  c expedie le loc bretagne  lanfains   autrit pens</td>\n",
       "      <td>Ker\\nchant\\n100% LOCAL\\nDecoupes de\\nPOULET\\nConditionné par LDC Bretagne\\nLanfains (22) 18\\nrais Classe A\\nOrigine FRANCE. Prodtre 0 et +4\"C\\nOFFRE\\nSPECIALE\\nNE ELEVE PREPARE\\n100% LOCAL\\nDANS NOTRE REGION\\n1CUIS.DEJ. PLT SAT\\nKERCHANT FX 1\\nORIGINE France\\nVOLAILLE\\nFRANÇAISE\\nPrix/kg\\nPaids net\\nPrin apayer\\n1,000kg\\nto\\n005806444\\nA consommer jusqu au\\n27/09/18\\nR conserver entre D C et 4 C\\nExpedie Le\\nLOC BRETAGNE 22 LANFAINS\\n2.09.02\\n256-106-0/1818\\nAUTRIT\\nPENS\\n3 199660112 19192\\n</td>\n",
       "      <td>/319/966/021/9192/1.json</td>\n",
       "      <td>fish meat eggs</td>\n",
       "      <td>meat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         barcode  \\\n",
       "0  3199660476748   \n",
       "1  3199660219192   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      clean_text  \\\n",
       "0  ne eleve abattu en bretagne les eleveurs de bretagne decoupe de podlet noir ferfier labe caracteristiques certifiees fermiereleve en plein air duree delevage  jours minimum  de cereales alimente avec  de vegetaux mineraux et vitamines do mation  voir etiquette poidsprix a conserver entre oc et c a consommer cuit a caeurdate limite de co  le rheu certifie par certisimmeuble le millepertuis les landes dap produit frais classe a pour toute reclamation sadresser a fermiers dargoat bp ploufragan decoupe et conditionne par ldc bretagne bp  quintin homologation n la   ce  abattoir agree nfr  ce fltplt ferlr sat elbretpf  origine france yo volaise prixtrg poids net prix a payer kg lot    r consommer jusqu au r conserver entre o c et  c  expedie le  loc bretagne  lanfains  e a   au trit aste wwwconsignesdetrfr    \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                       ker chant  local decoupes de poulet conditionne par ldc bretagne lanfains   rais classe a origine france prodtre  et c offre speciale ne eleve prepare  local dans notre region cuisdej plt sat kerchant fx  origine france volaille francaise prixkg paids net prin apayer kg to  a consommer jusqu au  r conserver entre d c et  c expedie le loc bretagne  lanfains   autrit pens       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   fr_text  \\\n",
       "0  NE\\nELEVE\\nABATTU\\nEN BRETAGNE\\nLES ÉLEVEURS\\nDE BRETAGNE\\nDécoupe de\\nPodlet noir\\nferfier\\nlabe\\nCaractéristiques certifiées: Fermier-élevé en plein air. Durée d'élevage 81 jours minimum.\\n75% de céréales.\\nAlimenté avec 100% de végétaux, minéraux et vitamines do mation : voir étiquette poids/prix\\nA conserver entre O°C et +4°C -A consommer cuit à caeur-Date limite de co 35650 Le Rheu\\nCertifié par: CERTIS-Immeuble Le Millepertuis- Les Landes d'Ap\\nProduit frais\\nClasse A\\nPour toute réclamation, s'adresser à\\nFERMIERS D'ARGOAT: BP77-22440 PLOUFRAGAN\\nDécoupé et conditionné par: LDC Bretagne BP 256-2280 QUINTIN\\nHomologation\\nN° LA/02/75\\n099 002\\nCE\\n2\\nAbattoir agréé n'FR 22.099.002 CE\\n2FLT.PLT FER.LR SAT\\nEL.BRET.PF 2\\nORIGINE France\\nyo\\nVOLAISE\\nPrixtrg\\nPoids net\\nPrix a payer\\n0,240kg\\nLot\\n005809 19 45\\nR consommer jusqu au\\nR conserver entre O C et +4 C\\n10/04/18\\nExpedie Le 30/03/18\\nLOC BRETAGNE 22 LANFAINS\\n22.039.002\\ne01\\n172225-0/196A\\n3 19966014\\nAU TRIT ASTE\\nwww.CONSIGNESDETRFR\\n   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Ker\\nchant\\n100% LOCAL\\nDecoupes de\\nPOULET\\nConditionné par LDC Bretagne\\nLanfains (22) 18\\nrais Classe A\\nOrigine FRANCE. Prodtre 0 et +4\"C\\nOFFRE\\nSPECIALE\\nNE ELEVE PREPARE\\n100% LOCAL\\nDANS NOTRE REGION\\n1CUIS.DEJ. PLT SAT\\nKERCHANT FX 1\\nORIGINE France\\nVOLAILLE\\nFRANÇAISE\\nPrix/kg\\nPaids net\\nPrin apayer\\n1,000kg\\nto\\n005806444\\nA consommer jusqu au\\n27/09/18\\nR conserver entre D C et 4 C\\nExpedie Le\\nLOC BRETAGNE 22 LANFAINS\\n2.09.02\\n256-106-0/1818\\nAUTRIT\\nPENS\\n3 199660112 19192\\n   \n",
       "\n",
       "                     source   pnns_groups_1 pnns_groups_2  \n",
       "0  /319/966/047/6748/1.json  fish meat eggs          meat  \n",
       "1  /319/966/021/9192/1.json  fish meat eggs          meat  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.5 ms (started: 2021-03-01 15:39:54 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Brief look at the dataset\n",
    "print(f\"\"\"Shape of the dataset: {off.shape}\n",
    "\"\"\")\n",
    "print(f\"\"\"Columns types of the dataset: \n",
    "{off.dtypes}\n",
    "\"\"\")\n",
    "print(f\"\"\"Head of the dataset:\"\"\")\n",
    "display(off.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-female",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intimate-jonathan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 969 µs (started: 2021-03-01 10:58:54 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def basic_clean(text):\n",
    "    \"\"\"\n",
    "    A simple function to clean up the data. All the words that\n",
    "    are not designated as a stop word is then lemmatized after\n",
    "    encoding and basic regex parsing are performed.\n",
    "    \"\"\"\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english'\n",
    "                                           ) + nltk.corpus.stopwords.words(\n",
    "                                            'french') + ADDITIONAL_STOPWORDS\n",
    "    words = (unicodedata.normalize('NFKD', text)\n",
    "            .encode('ascii', 'ignore')\n",
    "            .decode('utf-8', 'ignore')\n",
    "            .lower())\n",
    "    # words = re.sub(\"\\d+\", \"\", words) # Remove numbers\n",
    "    words = re.sub(r'[^\\w\\s]', '', words).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expensive-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.12 s (started: 2021-03-01 10:58:55 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Apply the function\n",
    "words = basic_clean(''.join(str(df['fr_text'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surrounded-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avant has occurred 1643 times\n",
      "time: 35 ms (started: 2021-03-01 10:58:59 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# test that the output is not unique occurences\n",
    "from collections import Counter \n",
    "\n",
    "x = 'avant'\n",
    "d = Counter(words) \n",
    "print('{} has occurred {} times'.format(x, d[x])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-sandwich",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loop over the Function of Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "external-premiere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.34 ms (started: 2021-03-01 13:05:23 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Create a list of categories\n",
    "categories_1 = list(df.pnns_groups_1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "noted-tongue",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.22 s (started: 2021-03-01 13:05:26 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize texts for the whole column \n",
    "words_global = basic_clean(''.join(str(df['fr_text'].tolist())))\n",
    "\n",
    "# Create a dict of tokenized texts per categories\n",
    "words_categories_1 = {k: basic_clean(''.join(\n",
    "    str(df['fr_text'][df['pnns_groups_1'] == k].tolist()))\n",
    "                                    ) for k in categories_1\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "reported-corporation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.99 s (started: 2021-03-01 15:41:16 +01:00)\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "# Instanciate the df that will store the output of the whole loop\n",
    "main_df_list = []\n",
    "\n",
    "# Loop over the number of n-grams\n",
    "for ng in range(1, 5):\n",
    "    \n",
    "    # Create an empty list to store all the dataframes before merging them\n",
    "    df_list = []\n",
    "    # n_grams = pd.DataFrame(columns=['pattern', 'n_gram_size', 'global_occurences',] + categories_1)\n",
    "    \n",
    "    # Get the n-grams for all the categories\n",
    "    n_grams_global = (pd.Series(nltk.ngrams(words, ng)).value_counts())\n",
    "    df_list.append(\n",
    "        pd.DataFrame({'pattern': n_grams_global.index, \n",
    "                      'global_occurences': n_grams_global.values,\n",
    "                     })\n",
    "    )\n",
    "    \n",
    "    # Get the n-grams for each category:\n",
    "    for cat_k in words_categories_1.keys():\n",
    "        n_grams_cat = (pd.Series(nltk.ngrams(words_categories_1[cat_k], ng)).value_counts())\n",
    "        df_list.append(\n",
    "            pd.DataFrame({'pattern': n_grams_cat.index,\n",
    "                          cat_k: n_grams_cat.values,\n",
    "                         })\n",
    "        )\n",
    "    \n",
    "    # Concatenate the dataframes at the end of the iteration\n",
    "    n_df = reduce(lambda left, right: pd.merge(left, right, on='pattern'), df_list)\n",
    "    \n",
    "    # Create a variable to specify the number of n-grams of the output \n",
    "    n_gram_size = str(ng) + '-grams'\n",
    "    n_df.insert(0,'n_gram_size',n_gram_size)\n",
    "    \n",
    "    # Append the dataframe of this n-gram\n",
    "    main_df_list.append(n_df)\n",
    "\n",
    "# Concatenate the dataframes after the loop\n",
    "ngrams_df = pd.concat(main_df_list, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "defensive-latter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.65 ms (started: 2021-03-01 15:04:49 +01:00)\n"
     ]
    }
   ],
   "source": [
    "len(ngrams_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "shaped-piano",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram_size</th>\n",
       "      <th>pattern</th>\n",
       "      <th>global_occurences</th>\n",
       "      <th>fish meat eggs</th>\n",
       "      <th>sugary snacks</th>\n",
       "      <th>cereals and potatoes</th>\n",
       "      <th>milk and dairy products</th>\n",
       "      <th>fat and sauces</th>\n",
       "      <th>fruits and vegetables</th>\n",
       "      <th>salty snacks</th>\n",
       "      <th>beverages</th>\n",
       "      <th>composite foods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2-grams</td>\n",
       "      <td>(code, barresnfigurant)</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2-grams</td>\n",
       "      <td>(recyclernconsigne, pouvant)</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>2-grams</td>\n",
       "      <td>(tsa, 91431n91343)</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>2-grams</td>\n",
       "      <td>(equilibrez, bougezn)</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>2-grams</td>\n",
       "      <td>(consommateurs, tsa)</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_gram_size                       pattern  global_occurences  \\\n",
       "420     2-grams       (code, barresnfigurant)                 35   \n",
       "421     2-grams  (recyclernconsigne, pouvant)                 33   \n",
       "422     2-grams            (tsa, 91431n91343)                 31   \n",
       "423     2-grams         (equilibrez, bougezn)                 28   \n",
       "424     2-grams          (consommateurs, tsa)                 28   \n",
       "\n",
       "     fish meat eggs  sugary snacks  cereals and potatoes  \\\n",
       "420               5              5                     4   \n",
       "421               5              1                     2   \n",
       "422               7              5                     2   \n",
       "423               4              8                     5   \n",
       "424               6              6                     1   \n",
       "\n",
       "     milk and dairy products  fat and sauces  fruits and vegetables  \\\n",
       "420                        2               3                      3   \n",
       "421                        9               1                      4   \n",
       "422                        2               2                      2   \n",
       "423                        4               1                      2   \n",
       "424                        2               2                      2   \n",
       "\n",
       "     salty snacks  beverages  composite foods  \n",
       "420             3          2                8  \n",
       "421             2          1                8  \n",
       "422             4          2                5  \n",
       "423             1          1                2  \n",
       "424             1          4                4  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.2 ms (started: 2021-03-01 15:04:22 +01:00)\n"
     ]
    }
   ],
   "source": [
    "ngrams_df[420:425]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
